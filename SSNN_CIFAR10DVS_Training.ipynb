{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "SSNN_CIFAR10DVS_Training.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SSNN on CIFAR10-DVS â€” Reproducible Training (Colab)\n",
        "**Model:** Shrinking Spiking Neural Network (SSNN) with four stages and shrinking timesteps `[8, 6, 4, 2]`  \n",
        "**Datasets:** CIFAR10-DVS ([40])  \n",
        "**Paper section:** *Training Configuration / Table 1*  \n",
        "**Note:** This notebook matches the configuration in Table 1. Edit the hyperparameters in the next cell if your table differs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Runtime: Google Colab\n",
        "# Installs\n",
        "!pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install snntorch tonic==1.4.3 einops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, math, random, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from einops import rearrange\n",
        "\n",
        "# spiking + datasets\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils as snnutils\n",
        "import tonic\n",
        "from tonic import transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('device:', device)\n",
        "\n",
        "# Reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== Config matching Table 1 (edit to match your paper) =====\n",
        "CFG = {\n",
        "    \"batch_size\": 32,          # Table 1: Batch size\n",
        "    \"epochs\": 5,               # Table 1: Epochs (increase for full training)\n",
        "    \"lr\": 1e-3,                # Table 1: Learning rate\n",
        "    \"weight_decay\": 1e-4,      # Table 1: Weight decay\n",
        "    \"beta\": 0.9,               # LIF decay\n",
        "    \"n_time_bins\": 8,          # Max time bins for CIFAR10-DVS frames\n",
        "    \"timesteps_per_stage\": [8,6,4,2],  # Shrinking schedule\n",
        "    \"aux_loss_weights\": [0.3, 0.2, 0.1], # stage1, stage2, stage3 auxiliary heads\n",
        "    \"num_workers\": 2\n",
        "}\n",
        "print(CFG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== Dataset: CIFAR10-DVS (tonic) =====\n",
        "save_dir = \"/content/data\"\n",
        "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "sensor_size = tonic.datasets.CIFAR10DVS.sensor_size  # (128,128,2)\n",
        "\n",
        "frame_transform = transforms.ToFrame(\n",
        "    sensor_size=sensor_size,\n",
        "    n_time_bins=CFG[\"n_time_bins\"]\n",
        ")\n",
        "\n",
        "trainset = tonic.datasets.CIFAR10DVS(save_to=save_dir, train=True, transform=frame_transform)\n",
        "testset  = tonic.datasets.CIFAR10DVS(save_to=save_dir, train=False, transform=frame_transform)\n",
        "\n",
        "# Pad sequences to the same temporal length within a batch\n",
        "collate_fn = tonic.collation.PadTensors(batch_first=True)  # output: (B, T, C, H, W)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=CFG[\"batch_size\"], shuffle=True,\n",
        "                         collate_fn=collate_fn, num_workers=CFG[\"num_workers\"], pin_memory=True)\n",
        "testloader  = DataLoader(testset,  batch_size=CFG[\"batch_size\"], shuffle=False,\n",
        "                         collate_fn=collate_fn, num_workers=CFG[\"num_workers\"], pin_memory=True)\n",
        "\n",
        "# Peek\n",
        "xb, yb = next(iter(trainloader))\n",
        "print('batch frames:', xb.shape, 'labels:', yb.shape)  # (B, T, C=2, H=128, W=128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== Model: 4-stage SSNN with shrinking timesteps =====\n",
        "# Each stage: Conv2d -> BN -> LIF -> (optional pooling)\n",
        "# Temporal alignment: lightweight transformer encoder across time between stages\n",
        "\n",
        "class TemporalAlign(nn.Module):\n",
        "    def __init__(self, embed_dim, nhead=4, dim_feedforward=256, num_layers=1):\n",
        "        super().__init__()\n",
        "        layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=nhead,\n",
        "                                           dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers)\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, C, H, W) -> flatten spatial, encode time, restore\n",
        "        B, T, C, H, W = x.shape\n",
        "        x_flat = x.view(B, T, C*H*W)\n",
        "        x_enc = self.encoder(x_flat)\n",
        "        return x_enc.view(B, T, C, H, W)\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, beta=0.9, pool=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.bn   = nn.BatchNorm2d(out_ch)\n",
        "        self.lif  = snn.Leaky(beta=beta, learn_beta=False)\n",
        "        self.pool = nn.AvgPool2d(2) if pool else nn.Identity()\n",
        "    def forward(self, x_t, mem=None):\n",
        "        # x_t: (B, C, H, W) for a single time step\n",
        "        z = self.conv(x_t)\n",
        "        z = self.bn(z)\n",
        "        spk, mem = self.lif(z, mem)\n",
        "        spk = self.pool(spk)\n",
        "        return spk, mem\n",
        "\n",
        "class Readout(nn.Module):\n",
        "    def __init__(self, in_ch, n_classes=10):\n",
        "        super().__init__()\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc  = nn.Linear(in_ch, n_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.gap(x).flatten(1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class SSNN(nn.Module):\n",
        "    def __init__(self, beta=0.9, n_classes=10, t_per_stage=(8,6,4,2)):\n",
        "        super().__init__()\n",
        "        self.t_per_stage = t_per_stage\n",
        "        self.stage1 = Stage(2,   32, beta=beta, pool=True)\n",
        "        self.stage2 = Stage(32,  64, beta=beta, pool=True)\n",
        "        self.stage3 = Stage(64, 128, beta=beta, pool=True)\n",
        "        self.stage4 = Stage(128,256, beta=beta, pool=True)\n",
        "\n",
        "        self.align12 = TemporalAlign(embed_dim=32*64*64,  nhead=4, num_layers=1)\n",
        "        self.align23 = TemporalAlign(embed_dim=64*32*32,  nhead=4, num_layers=1)\n",
        "        self.align34 = TemporalAlign(embed_dim=128*16*16, nhead=4, num_layers=1)\n",
        "\n",
        "        # Early classifiers after stage 1-3\n",
        "        self.aux1 = Readout(32, n_classes)\n",
        "        self.aux2 = Readout(64, n_classes)\n",
        "        self.aux3 = Readout(128, n_classes)\n",
        "        # Final head\n",
        "        self.head = Readout(256, n_classes)\n",
        "\n",
        "    def forward(self, x, train_aux=False):\n",
        "        # x: (B, T, C=2, H, W)\n",
        "        B, T, C, H, W = x.shape\n",
        "        T1, T2, T3, T4 = self.t_per_stage\n",
        "\n",
        "        mem1 = mem2 = mem3 = mem4 = None\n",
        "        logits_final = []\n",
        "        logits_aux1  = []\n",
        "        logits_aux2  = []\n",
        "        logits_aux3  = []\n",
        "\n",
        "        # process stage1 across T1 steps\n",
        "        s1_seq = []\n",
        "        for t in range(min(T, T1)):\n",
        "            spk1, mem1 = self.stage1(x[:, t], mem1)\n",
        "            s1_seq.append(spk1)\n",
        "            if train_aux:\n",
        "                logits_aux1.append(self.aux1(spk1))\n",
        "        s1 = torch.stack(s1_seq, dim=1)  # (B, T1, C, H, W)\n",
        "\n",
        "        # align time for stage2 input\n",
        "        s1_aligned = self.align12(s1)\n",
        "\n",
        "        # stage2 across T2 steps\n",
        "        s2_seq = []\n",
        "        for t in range(min(s1_aligned.shape[1], T2)):\n",
        "            spk2, mem2 = self.stage2(s1_aligned[:, t], mem2)\n",
        "            s2_seq.append(spk2)\n",
        "            if train_aux:\n",
        "                logits_aux2.append(self.aux2(spk2))\n",
        "        s2 = torch.stack(s2_seq, dim=1)\n",
        "\n",
        "        # align and stage3\n",
        "        s2_aligned = self.align23(s2)\n",
        "        s3_seq = []\n",
        "        for t in range(min(s2_aligned.shape[1], T3)):\n",
        "            spk3, mem3 = self.stage3(s2_aligned[:, t], mem3)\n",
        "            s3_seq.append(spk3)\n",
        "            if train_aux:\n",
        "                logits_aux3.append(self.aux3(spk3))\n",
        "        s3 = torch.stack(s3_seq, dim=1)\n",
        "\n",
        "        # align and stage4\n",
        "        s3_aligned = self.align34(s3)\n",
        "        s4_seq = []\n",
        "        for t in range(min(s3_aligned.shape[1], T4)):\n",
        "            spk4, mem4 = self.stage4(s3_aligned[:, t], mem4)\n",
        "            s4_seq.append(spk4)\n",
        "            # final head per time step\n",
        "            logits_final.append(self.head(spk4))\n",
        "        # average logits over time\n",
        "        logit = torch.stack(logits_final, dim=1).mean(dim=1)\n",
        "\n",
        "        outs = {\"logit\": logit}\n",
        "        if train_aux:\n",
        "            outs[\"aux1\"] = torch.stack(logits_aux1, dim=1).mean(dim=1)\n",
        "            outs[\"aux2\"] = torch.stack(logits_aux2, dim=1).mean(dim=1)\n",
        "            outs[\"aux3\"] = torch.stack(logits_aux3, dim=1).mean(dim=1)\n",
        "        return outs\n",
        "\n",
        "model = SSNN(beta=CFG[\"beta\"], n_classes=10, t_per_stage=tuple(CFG[\"timesteps_per_stage\"])).to(device)\n",
        "sum_params = sum(p.numel() for p in model.parameters())\n",
        "print(model.__class__.__name__, \"params:\", sum_params/1e6, \"M\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "executionInfo": {}
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== Training / Evaluation =====\n",
        "def accuracy(logits, targets):\n",
        "    return (logits.argmax(dim=1) == targets).float().mean().item()\n",
        "\n",
        "def train_one_epoch(model, loader, opt, epoch):\n",
        "    model.train()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    w1, w2, w3 = CFG[\"aux_loss_weights\"]\n",
        "    total, acc = 0., 0.\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        outs = model(xb, train_aux=True)\n",
        "        loss = ce(outs[\"logit\"], yb)\n",
        "        loss_aux = w1*ce(outs[\"aux1\"], yb) + w2*ce(outs[\"aux2\"], yb) + w3*ce(outs[\"aux3\"], yb)\n",
        "        loss = loss + loss_aux\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        opt.step()\n",
        "        total += loss.item()*xb.size(0)\n",
        "        acc   += (outs[\"logit\"].argmax(1) == yb).sum().item()\n",
        "    n = len(loader.dataset)\n",
        "    return total/n, acc/n\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    total, acc = 0., 0.\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        outs = model(xb, train_aux=False)\n",
        "        loss = ce(outs[\"logit\"], yb)\n",
        "        total += loss.item()*xb.size(0)\n",
        "        acc   += (outs[\"logit\"].argmax(1) == yb).sum().item()\n",
        "    n = len(loader.dataset)\n",
        "    return total/n, acc/n\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, CFG[\"epochs\"]+1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, trainloader, opt, epoch)\n",
        "    te_loss, te_acc = evaluate(model, testloader)\n",
        "    print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} | val loss {te_loss:.4f} acc {te_acc:.3f}\")\n",
        "    if te_acc > best_acc:\n",
        "        best_acc = te_acc\n",
        "        torch.save(model.state_dict(), \"/content/ssnn_cifar10dvs.pt\")\n",
        "print(\"Best val acc:\", round(best_acc, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code availability\n",
        "This notebook constitutes the *Google Colab file* requested by the reviewer.  \n",
        "It implements SSNN with four shrinking stages `[8,6,4,2]`, auxiliary heads, and the training\n",
        "configuration of Table 1. Replace `CFG` values to match your exact table if needed."
      ]
    }
  ]
}